param:
  # corpus
  corpus: librispeech
  label_type: character
  train_data_size: train100h

  # features
  feature: fbank
  input_size: 120
  splice: 5
  num_stack: 2
  num_skip: 2
  # NOTE: teacher CTC used 20ms frame stacking

  # topology
  encoder_type: student_cnn_compact_xe

  # optimization
  batch_size: 512
  # optimizer: adam
  optimizer: sgd
  # optimizer: momentum
  # optimizer: nestrov
  learning_rate: 1e-2
  num_epoch: 30

  # regularization
  weight_init: 0.1
  clip_grad_norm: 5.0
  dropout: 0.5
  weight_decay: 0
  decay_start_epoch: 6
  decay_rate: 0.5
  decay_patient_epoch: 2
  sort_stop_epoch: 6
  not_improved_patient_epoch: 3

  eval_start_epoch: 1
  print_step: 2000
  beam_width: 100

  teacher_model_path: /u/jp573469/inaguma/models/tensorflow/librispeech/ctc/character/train100h/blstm_ctc_320_5_rmsprop_lr1e-3_drop0.2_stack2_temp2_3
  teacher_temperature: 2  # inference of teacher
  student_temperature: 2  # training of student
